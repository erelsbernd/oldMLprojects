{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the first predictor (variable) and fit the model M1  \n",
    "\n",
    "• For k = 1, . . . , p − 1:  \n",
    "– Consider all p−k models that augment the predictor in Mk with one additional predictor.  \n",
    "– Choose the best among these p − k models and call it Mk+1. Best is defined as having smallest error on cross-validation.\n",
    "\n",
    "• Select the best model from among M1, . . . , Mp using cross-validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from scipy.stats import uniform\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing as mp\n",
    "%matplotlib inline\n",
    "score_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1847, 73)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data in dataframe\n",
    "col_names = ['X' + str(i) for i in range(73)]\n",
    "data = pd.read_excel(\"ozon.xlsx\", header = None, names = col_names)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1847, 72)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define x and y\n",
    "feature_cols = ['X' + str(i) for i in range(72)]\n",
    "x = data[feature_cols]\n",
    "y = data.X72\n",
    "data['X72'] = data['X72'].replace([0, 1], [-1, 1]) \n",
    "y = data['X72']\n",
    "standard_scaler = StandardScaler()\n",
    "x = pd.DataFrame(standard_scaler.fit_transform(x), columns = feature_cols)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94394213381555159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 553, train_size = 1292)\n",
    "Cs = np.linspace(0.001, 1001.0, num=2000, endpoint=False)\n",
    "\n",
    "# Designate distributions to sample hyperparameters from \n",
    "g_range = np.random.uniform(0.0, 2.3, 60).astype(float)\n",
    "C_range = np.random.normal(0.1, 14.0, 100).astype(float)\n",
    "\n",
    "# Check that gamma>0 and C>0 \n",
    "C_range[C_range < 0] = 0.0001\n",
    "\n",
    "hyperparameters = {'gamma': list(g_range), \n",
    "                    'C': list(C_range)}\n",
    "\n",
    "\n",
    "# Run randomized search with range of hyperparameter values\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "randomCV = RandomizedSearchCV(svm, param_distributions=hyperparameters, n_iter=20)\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "# Identify optimal hyperparameter values and add to list\n",
    "best_gamma  = randomCV.best_params_['gamma']\n",
    "best_C      = randomCV.best_params_['C']\n",
    "\n",
    "# Train SVM and output predictions\n",
    "rbfSVM = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "rbfSVM.probability=True\n",
    "rbfSVM.fit(x_train, y_train)\n",
    "svm_predictions = rbfSVM.predict(x_test)\n",
    "y_pred_prob = rbfSVM.predict_proba(x_test)[:, 1]\n",
    "y_pred = rbfSVM.predict(x_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 72 different models for each feature, pick the best one and use that as the base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_scores = np.zeros(shape = (72,2))\n",
    "\n",
    "for i in range(72):\n",
    "    # split data\n",
    "    new_x = x['X' + str(i)]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(new_x.values[:,np.newaxis], y, test_size = .3, train_size = .7)\n",
    "    # Train SVM and output predictions\n",
    "    rbfSVM = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "    rbfSVM.probability=True\n",
    "    rbfSVM.fit(x_train, y_train)\n",
    "    svm_predictions = rbfSVM.predict(x_test)\n",
    "    y_pred_prob = rbfSVM.predict_proba(x_test)[:, 1]\n",
    "    y_pred = rbfSVM.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores[i][0] = i\n",
    "    accuracy_scores[i][1] = score\n",
    "\n",
    "    \n",
    "#get the feature that perform best and use that as the base    \n",
    "x_max,y_max = accuracy_scores.max(axis=0)\n",
    "high_score,index = np.where(accuracy_scores == y_max)\n",
    "max_accuracy = y_max\n",
    "high_score= high_score[0]\n",
    "index = index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1847, 1)\n",
      "(1847, 72)\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(index))+ list(range(index+1,72))\n",
    "new_x = pd.DataFrame(x['X' + str(index)])\n",
    "print(new_x.shape)\n",
    "print(x.shape)\n",
    "best_indices_list = []\n",
    "best_indices_list.append(index)\n",
    "previous_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_selection(i):\n",
    "\n",
    "    # add the new feature to x\n",
    "    temp_x = new_x.copy()\n",
    "    temp_x['X' + str(i)] = x['X' + str(i)]\n",
    "\n",
    "    # split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(temp_x, y, test_size = 553, train_size = 1292)\n",
    "\n",
    "    # fit model\n",
    "    rbfSVM = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "    rbfSVM.probability=True\n",
    "    rbfSVM.fit(x_train, y_train)\n",
    "    svm_predictions = rbfSVM.predict(x_test)\n",
    "    y_pred_prob = rbfSVM.predict_proba(x_test)[:, 1]\n",
    "    y_pred = rbfSVM.predict(x_test)\n",
    "\n",
    "    #add performance score to accuracy_list\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    return i, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use multiprocessing to run forward_selection function and pick the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(71):\n",
    "    pool = mp.Pool(processes=4)\n",
    "    results = pool.map(forward_selection, indices)\n",
    "    pool.terminate()\n",
    "    \n",
    "    #get the feature that performs best and add that\n",
    "    scores_list = [tup[1] for tup in results]\n",
    "    indices_list = [tup[0] for tup in results]\n",
    "    high_score = max(scores_list)\n",
    "    max_index = scores_list.index(high_score) \n",
    "    index = indices_list[max_index]\n",
    "\n",
    "    \n",
    "    if (high_score > previous_score):\n",
    "        new_x['X' + str(index)] = x['X' + str(index)]\n",
    "        indices.remove(index)\n",
    "        best_indices_list.append(index)\n",
    "        previous_score = high_score\n",
    "    \n",
    "    # split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(new_x, y, test_size = 553, train_size = 1292)\n",
    "    #find optimal parameters for next go around\n",
    "    Cs = np.linspace(0.001, 1001.0, num=2000, endpoint=False)\n",
    "    # Designate distributions to sample hyperparameters from \n",
    "    g_range = np.random.uniform(0.0, 2.3, 60).astype(float)\n",
    "    C_range = np.random.normal(0.1, 14.0, 100).astype(float)\n",
    "    # Check that gamma>0 and C>0 \n",
    "    C_range[C_range < 0] = 0.0001\n",
    "    hyperparameters = {'gamma': list(g_range), \n",
    "                        'C': list(C_range)}\n",
    "    # Run randomized search with range of hyperparameter values\n",
    "    svm = SVC(kernel='rbf', probability=True)\n",
    "    randomCV = RandomizedSearchCV(svm, param_distributions=hyperparameters, n_iter=5)\n",
    "    randomCV.fit(x_train, y_train)\n",
    "\n",
    "    # Identify optimal hyperparameter values and save\n",
    "    best_gamma  = randomCV.best_params_['gamma']\n",
    "    best_C      = randomCV.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices used in best model [1, 65, 45, 22, 44, 47]\n",
      "Best Model Score 0.960216998192\n"
     ]
    }
   ],
   "source": [
    "print(\"Indices used in best model\", best_indices_list)\n",
    "print(\"Best Model Score\", previous_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
